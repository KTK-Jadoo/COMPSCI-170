\documentclass[11pt]{article}
\usepackage{amsmath,textcomp,amssymb,geometry,graphicx,enumerate}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}


\def\Name{Kartikeya Sharma}  % Your name
\def\SID{3037376860}  % Your student ID number
\def\Homework{12 } % Number of Homework
\def\Session{Fall 2024}


\title{COMPSCI 170 Fall 2024 --- Homework \Homework Solutions}
\author{\Name, SID \SID}
\markboth{CS70--\Session\  Homework \Homework\ \Name}{CS170 -- \Session\ Homework \Homework\ \Name}
\pagestyle{myheadings}
\date{\today}

\usepackage{amssymb}

% Define the 'solution' environment
\newenvironment{solution}{%
    \par\noindent\textbf{Solution:}\par%
}{\par}

\begin{document}

\maketitle

\section*{Q1 Study Group}

\textbf{none}

\newpage


\section*{Q2 Upper Bounds on Algorithms for NP Problems}

\subsection*{(a) A $O(2^n m)$-time Algorithm for 3-SAT}

\begin{solution}
We are tasked with designing an algorithm that solves the 3-SAT problem in $O(2^n m)$ time. Recall that 3-SAT involves $n$ variables $x_1, x_2, \dots, x_n$ and $m$ clauses, where each clause contains at most three literals.

\textbf{Algorithm Description:}
\begin{itemize}
    \item Enumerate all $2^n$ possible truth assignments for the $n$ variables.
    \begin{itemize}
        \item For each truth assignment, assign each variable $x_i$ to either true or false.
    \end{itemize}
    \item For each truth assignment, check if it satisfies all $m$ clauses.
    \begin{itemize}
        \item This takes $O(m)$ time per assignment because we evaluate each clause (at most three literals per clause).
    \end{itemize}
    \item If a truth assignment satisfies all $m$ clauses, return that assignment as the solution.
    \item If no assignment satisfies all clauses after checking all $2^n$ possibilities, report that no solution exists.
\end{itemize}

\textbf{Runtime Analysis:}
\begin{itemize}
    \item Generating all $2^n$ truth assignments requires $O(2^n)$ time.
    \item For each assignment, checking all $m$ clauses requires $O(m)$ time.
    \item Therefore, the total runtime is $O(2^n \cdot m)$.
\end{itemize}

This algorithm is correct because it exhaustively checks all possible assignments and verifies whether any satisfy all clauses.
\end{solution}

---

\subsection*{(b) A $O(2^{n^c})$-time Algorithm for Any Problem in NP}

\begin{solution}
We are tasked with designing an algorithm that solves any problem in NP in $O(2^{n^c})$ time, where $c$ is a constant. We will leverage the fact that 3-SAT is NP-hard.

\textbf{Algorithm Description:}
\begin{itemize}
    \item Given a problem $P$ in NP, construct a nondeterministic polynomial-time verifier for $P$. This verifier checks whether a given certificate is valid for the problem $P$.
    \item Use the fact that any problem in NP can be reduced to 3-SAT in polynomial time. Let $n$ be the size of the input to $P$.
    \item Reduce the problem $P$ to an equivalent instance of 3-SAT with $n'$ variables and $m'$ clauses, where $n'$ and $m'$ are polynomial in $n$ (i.e., $n', m' = O(n^k)$ for some constant $k$).
    \item Solve the 3-SAT instance using the $O(2^{n'} m')$ algorithm from part (a). Since $n' = O(n^k)$, the runtime becomes $O(2^{n^c})$, where $c = k$.
\end{itemize}

\textbf{Runtime Analysis:}
\begin{itemize}
    \item The reduction from $P$ to 3-SAT takes polynomial time.
    \item Solving the resulting 3-SAT instance takes $O(2^{n^c})$ time, as shown in part (a).
\end{itemize}

Thus, any problem in NP can be solved in $O(2^{n^c})$ time, proving that NP $\subseteq$ EXP.
\end{solution}

---

\subsection*{(c) Is the Halting Problem NP-hard? Is it NP-complete?}

\begin{solution}
\textbf{1. NP-hardness:}
\begin{itemize}
    \item To prove NP-hardness, we need to show that every problem in NP can be reduced to the halting problem in polynomial time.
    \item Since 3-SAT is NP-hard, and we have a polynomial-time reduction from 3-SAT to the halting problem, the halting problem is NP-hard.
\end{itemize}

\textbf{2. NP-completeness:}
\begin{itemize}
    \item A problem is NP-complete if it is both NP-hard and in NP.
    \item The halting problem is \textbf{not in NP} because there is no polynomial-time verifier for the halting problem. Specifically, verifying whether a program halts requires simulating its execution, which cannot be done in polynomial time due to the undecidability of the halting problem.
\end{itemize}

\textbf{Conclusion:}
\begin{itemize}
    \item The halting problem is NP-hard but not NP-complete because it is not in NP.
\end{itemize}
\end{solution}

\newpage

\section*{Q3 k-XOR}

\subsection*{(a) Reduction from Max-Cut to 2-XOR}

\begin{solution}
\textbf{Reduction Description:}
\begin{itemize}
    \item In the 2-XOR problem, each clause is of the form \( x_i \oplus x_j = 1 \), which is equivalent to stating that \( x_i \) and \( x_j \) must have opposite truth values for the clause to be satisfied.
    \item In the Max-Cut problem, we are given an undirected graph \( G = (V, E) \) and an integer \( \alpha \). The goal is to find a partition of \( V \) into two disjoint sets \( S \) and \( V \setminus S \) such that at least \( \alpha \) edges have endpoints in different sets.
    \item To reduce Max-Cut to 2-XOR:
    \begin{itemize}
        \item Create one variable \( x_v \) for each vertex \( v \in V \). Assign \( x_v = 0 \) if \( v \in S \) and \( x_v = 1 \) if \( v \in V \setminus S \).
        \item For each edge \( (u, v) \in E \), add a 2-XOR clause \( x_u \oplus x_v = 1 \). This ensures that \( x_u \) and \( x_v \) must be in different sets (i.e., the edge is "cut").
    \end{itemize}
    \item Solving the 2-XOR instance for \( \geq \alpha \) satisfied clauses directly corresponds to finding a cut in the graph with at least \( \alpha \) edges.
\end{itemize}

\textbf{Correctness Argument:}
\begin{itemize}
    \item Every edge in the Max-Cut graph corresponds to a clause in the 2-XOR instance.
    \item If a solution satisfies at least \( \alpha \) clauses in the 2-XOR instance, it directly implies that at least \( \alpha \) edges are cut in the corresponding Max-Cut solution.
    \item Conversely, any cut of \( \geq \alpha \) edges in the Max-Cut problem corresponds to a truth assignment satisfying \( \geq \alpha \) clauses in the 2-XOR instance.
    \item Therefore, the reduction is correct and polynomial-time.
\end{itemize}
\end{solution}

---

\subsection*{(b) Reduction from 3-XOR to 4-XOR}

\begin{solution}
\textbf{Reduction Description:}
\begin{itemize}
    \item In the 3-XOR problem, each clause involves exactly three variables, and the clause is true if the XOR of the three variables is 1 (i.e., an odd number of the variables are true).
    \item In the 4-XOR problem, each clause involves exactly four variables, and the clause is true if the XOR of the four variables is 1.
    \item To reduce 3-XOR to 4-XOR:
    \begin{itemize}
        \item For each 3-XOR clause \( x_i \oplus x_j \oplus x_k = 1 \), introduce a new variable \( y \) and replace the clause with two 4-XOR clauses:
        \begin{align*}
            x_i \oplus x_j \oplus y \oplus 0 &= 1, \\
            y \oplus x_k \oplus 0 \oplus 0 &= 1.
        \end{align*}
        \item This ensures that the truth assignment for \( x_i, x_j, x_k \) in the original 3-XOR clause is preserved in the transformed 4-XOR instance by linking \( y \) to the variables appropriately.
    \end{itemize}
\end{itemize}

\textbf{Correctness Argument:}
\begin{itemize}
    \item The new variable \( y \) ensures consistency between the two 4-XOR clauses, effectively encoding the original 3-XOR clause.
    \item If the original 3-XOR clause is satisfiable, the corresponding 4-XOR instance will also be satisfiable, as \( y \) can always be chosen to satisfy the new clauses.
    \item Conversely, if the 4-XOR instance derived from a 3-XOR clause is satisfiable, the truth assignments for \( x_i, x_j, x_k \) in the original problem can be reconstructed from the satisfiable assignment of \( y \).
    \item This reduction is polynomial-time, as each 3-XOR clause is replaced by exactly two 4-XOR clauses with the addition of one auxiliary variable.
\end{itemize}
\end{solution}

\newpage

\section*{Q4 Dominating Set}

\subsection*{Dominating Set is NP-Complete}

\begin{solution}
We aim to show that the Minimum Dominating Set problem is NP-complete. To do so, we proceed as follows:

\textbf{1. Dominating Set is in NP:}
\begin{itemize}
    \item A dominating set of size \( k \) is a subset \( D \subseteq V \) such that every vertex \( v \in V \setminus D \) is adjacent to at least one vertex in \( D \).
    \item Given a candidate set \( D \), we can verify in polynomial time whether it is a dominating set:
    \begin{itemize}
        \item For each vertex \( v \in V \setminus D \), check if there is at least one neighbor in \( D \). This requires \( O(|V| + |E|) \) time.
        \item Check if \( |D| \leq k \).
    \end{itemize}
    \item Since the verification can be performed in polynomial time, the problem is in NP.
\end{itemize}

\textbf{2. Reduction from Vertex Cover:}
\begin{itemize}
    \item To show NP-hardness, we reduce from the Vertex Cover problem, which is known to be NP-complete.
    \item Recall the Vertex Cover problem:
    \begin{itemize}
        \item Input: A graph \( G = (V, E) \) and an integer \( k \).
        \item Output: Does there exist a set \( C \subseteq V \) of size at most \( k \) such that every edge in \( E \) is incident to at least one vertex in \( C \)?
    \end{itemize}
    \item Reduction: Construct an instance of the Minimum Dominating Set problem from an instance of the Vertex Cover problem:
    \begin{itemize}
        \item Let the graph \( G = (V, E) \) from Vertex Cover be the same graph for the Dominating Set instance.
        \item Set the same integer \( k \) for the dominating set size.
    \end{itemize}
    \item Claim: \( G \) has a vertex cover of size \( k \) if and only if \( G \) has a dominating set of size \( k \):
    \begin{itemize}
        \item (\( \Rightarrow \)) If \( C \) is a vertex cover of size \( k \), then \( C \) is also a dominating set. Every edge is incident to at least one vertex in \( C \), so all vertices are either in \( C \) or adjacent to a vertex in \( C \).
        \item (\( \Leftarrow \)) If \( D \) is a dominating set of size \( k \), then \( D \) is also a vertex cover. For every edge \( (u, v) \), at least one of \( u \) or \( v \) must be in \( D \), since otherwise the edge would have no incident vertex in \( D \), violating the definition of a dominating set.
    \end{itemize}
    \item Thus, solving the Minimum Dominating Set problem for \( G \) and \( k \) also solves the Vertex Cover problem for \( G \) and \( k \).
\end{itemize}

\textbf{3. Conclusion:}
\begin{itemize}
    \item We have shown that Dominating Set is in NP.
    \item We have reduced Vertex Cover to Dominating Set in polynomial time.
    \item Therefore, the Minimum Dominating Set problem is NP-complete.
\end{itemize}
\end{solution}

\newpage

\section*{Q5 Approximating Independent Set}

\subsection*{(a) Example where Greedy Approximation is Not Optimal}

\begin{solution}
Consider the following graph \( G = (V, E) \):
\begin{itemize}
    \item \( V = \{a, b, c, d\} \)
    \item \( E = \{(a, b), (b, c), (c, d)\} \)
\end{itemize}

This graph forms a path: \( a \leftrightarrow b \leftrightarrow c \leftrightarrow d \).

\textbf{Greedy Algorithm's Behavior:}
\begin{itemize}
    \item The algorithm might start by picking vertex \( b \) (or any other vertex).
    \item It removes \( b \) and its neighbors \( a \) and \( c \) from the graph.
    \item The remaining vertex is \( d \), which the algorithm also selects.
    \item The resulting independent set is \( \{b, d\} \).
\end{itemize}

\textbf{Optimal Solution:}
\begin{itemize}
    \item The optimal independent set for this graph is \( \{a, c\} \) or \( \{b, d\} \), both of size 2. In this example, the greedy algorithm produces an optimal solution in one instance. In cases such as cycles of length n, greedy can perform worse.
\end{itemize}
\end{solution}

\subsection*{(b) Approximation Ratio of the Greedy Algorithm}

\begin{solution}
    
The approximation ratio of the greedy algorithm can be analyzed as follows:

\textbf{Degree Bound:}
\begin{itemize}
    \item The algorithm selects a vertex \( v \) in each iteration and removes \( v \) and all its neighbors from the graph.
    \item Since the degree of any vertex \( v \) is at most \( d \), at most \( d+1 \) vertices (including \( v \)) are removed in each iteration.
\end{itemize}

\textbf{Approximation Ratio:}
\begin{itemize}
    \item Let \( I^* \) denote the size of the optimal independent set.
    \item Each vertex added to the independent set \( I \) during the algorithm eliminates at most \( d+1 \) vertices from consideration.
    \item Therefore, the size of the greedy independent set \( |I| \) satisfies:
    \[
    |I| \geq \frac{|I^*|}{d+1}.
    \]
    \item Thus, the approximation ratio of the greedy algorithm is at least \( \frac{1}{d+1} \).
\end{itemize}

\textbf{Runtime Analysis:}
\begin{itemize}
    \item The algorithm iterates over all vertices, removing \( O(d+1) \) vertices per iteration.
    \item Checking and removing vertices takes \( O(|E|) \) time in total.
    \item The overall runtime of the algorithm is \( O(|V| + |E|) \).
\end{itemize}

\textbf{Conclusion:}
The greedy algorithm provides a \( \frac{1}{d+1} \)-approximation for the Maximum Independent Set problem in graphs with degree bound \( d \) and runs in \( O(|V| + |E|) \) time.
\end{solution}



\end{document}
